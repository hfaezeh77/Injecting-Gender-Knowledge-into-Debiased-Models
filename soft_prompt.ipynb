{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AGbm9NUjrVh",
        "outputId": "732c9f4b-14af-42cd-a35c-dd5813e71363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stanza in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza) (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.22.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from stanza) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install stanza\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KLJQHezMX3Md",
        "outputId": "d6b0e81e-0842-4eb6-bfc9-6239da901070"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2323730c7fcc>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import stanza\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cclztUNnYAU5"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/NLP project/masked_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnTlbbtSYQFs"
      },
      "outputs": [],
      "source": [
        "data=data.drop(['Unnamed: 0'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yThT2hyqqtG"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqN1SIZZjbgE"
      },
      "outputs": [],
      "source": [
        "class DepTreeNode:\n",
        "    def __init__(self, map, head_node=None, head_rel=None):\n",
        "        self.position = map['id']-1\n",
        "        self.text = map['text']\n",
        "        self.lemma = map['lemma'] if 'lemma' in map else map['text']\n",
        "        self.upos = map['upos']\n",
        "        self.ner = map['ner'] if map['ner'] != 'O' else None\n",
        "        self.head_node = head_node\n",
        "        self.head_rel = head_rel\n",
        "\n",
        "    def set_head(self, node, rel):\n",
        "        self.head_node = node\n",
        "        self.head_rel = rel\n",
        "\n",
        "    def __str__(self):\n",
        "        return str({\n",
        "            \"text\": self.text,\n",
        "            \"lemma\": self.lemma,\n",
        "            \"upos\": self.upos,\n",
        "            \"ner\": self.ner,\n",
        "            \"head\": self.head_node.text if self.head_node else \"root\",\n",
        "            \"head_rel\": self.head_rel if self.head_rel else \"root\"\n",
        "        })\n",
        "\n",
        "class DepTree:\n",
        "    def __init__(self, doc):\n",
        "        self.root = None\n",
        "        self.nodes = []\n",
        "        self.doc = doc\n",
        "        self.build_tree()\n",
        "\n",
        "    def build_tree(self):\n",
        "        for sent in self.doc.to_dict():\n",
        "            for word in sent:\n",
        "                node = DepTreeNode(word, None, None)\n",
        "                self.nodes.append(node)\n",
        "        for sent in self.doc.sentences:\n",
        "            for word in sent.words:\n",
        "                node = self.nodes[word.id - 1]\n",
        "                if word.head == 0:\n",
        "                    self.root = node\n",
        "                else:\n",
        "                    node.set_head(self.nodes[word.head - 1], word.deprel)\n",
        "\n",
        "    def print_tree(self):\n",
        "        for node in self.nodes:\n",
        "            print(node.text, node.head_node)\n",
        "\n",
        "    def get_node_by_text(self, text):\n",
        "        for node in self.nodes:\n",
        "            if node.text == text:\n",
        "                return node\n",
        "        return None\n",
        "\n",
        "    def get_node_by_lemma(self, lemma):\n",
        "        for node in self.nodes:\n",
        "            if node.lemma == lemma:\n",
        "                return node\n",
        "        return None\n",
        "\n",
        "    def get_node_by_upos(self, upos):\n",
        "        for node in self.nodes:\n",
        "            if node.upos == upos:\n",
        "                return node\n",
        "        return None\n",
        "\n",
        "    def get_node_by_ner(self, ner):\n",
        "        results = []\n",
        "        for node in self.nodes:\n",
        "            if node.ner and ner in node.ner:\n",
        "                results.append(node)\n",
        "        return results\n",
        "\n",
        "\n",
        "nlp = stanza.Pipeline(lang='en', processors='tokenize,lemma,pos,depparse,ner', use_gpu=True)\n",
        "\n",
        "class SoftEmbedding(nn.Module):\n",
        "    def __init__(self, tokenizer, wte, device):\n",
        "        super(SoftEmbedding, self).__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.wte = wte\n",
        "        self.device = device\n",
        "        self.wte.requires_grad = False\n",
        "        self.id2token = {v: k for k, v in tokenizer.get_vocab().items()}\n",
        "        self.learned_embedding = self.initialize_embedding(wte)\n",
        "\n",
        "    def initialize_embedding(self,\n",
        "                             wte: nn.Embedding,\n",
        "                             n_tokens: int = 10,\n",
        "                             n_prompts: int = 1,\n",
        "                             random_range: float = 0.5,\n",
        "                             initialize_from_vocab: bool = True):\n",
        "        \"\"\"initializes learned embedding\n",
        "\n",
        "        Args:\n",
        "            same as __init__\n",
        "\n",
        "        Returns:\n",
        "            torch.float: initialized using original schemes\n",
        "        \"\"\"\n",
        "        embedding = nn.Sequential(\n",
        "            nn.Linear(wte.weight.size(1), 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, wte.weight.size(1))\n",
        "        )\n",
        "        for param in embedding.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        return embedding\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        tokens = tokens[0]\n",
        "        tree = DepTree(nlp(self.tokenizer.decode(tokens, skip_special_tokens=True)))\n",
        "        entities = tree.get_node_by_ner(\"PERSON\")\n",
        "\n",
        "        input_embedding = self.wte(tokens)\n",
        "        max_length = input_embedding.size(0)\n",
        "\n",
        "        token_positions = []\n",
        "        for i, token in enumerate(map(lambda x: self.id2token[x.item()], tokens)):\n",
        "            if token == \"[CLS]\" or token == \"[SEP]\":\n",
        "                continue\n",
        "            if len(token_positions) >= 1 and token.startswith(\"##\"):\n",
        "                token_positions[-1].append(i)\n",
        "            else:\n",
        "                token_positions.append([i])\n",
        "\n",
        "        if len(entities) > 0:\n",
        "            entity_embeddings = []\n",
        "            for ent in entities:\n",
        "                with torch.no_grad():\n",
        "                    ent_tokens = self.tokenizer(f'{ent.text}', return_tensors=\"pt\", add_special_tokens=False).input_ids.squeeze(0).to(self.device)\n",
        "                    ent_embedding = self.wte(ent_tokens)\n",
        "                learned_embedding = self.learned_embedding(ent_embedding)\n",
        "                entity_embeddings.append((learned_embedding, token_positions[ent.position]))  # Store the learned embedding and position\n",
        "\n",
        "            padded_embedding = torch.zeros_like(input_embedding)\n",
        "            for ent_emb, pos in entity_embeddings:\n",
        "                if pos == ent_emb.size()[0]:\n",
        "                    padded_embedding[tuple(pos), :] = ent_emb\n",
        "                # else:\n",
        "                #     print(self.tokenizer(f'{ent.text}', return_tensors=\"pt\", add_special_tokens=False).input_ids)\n",
        "                #     print(tokens)\n",
        "\n",
        "            final_embedding = torch.cat([input_embedding, padded_embedding], dim=0)\n",
        "            final_embedding = torch.mean(final_embedding, dim=0)\n",
        "        else:\n",
        "            final_embedding = input_embedding\n",
        "\n",
        "        return final_embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu7AG4G5PIuU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "batch_size=16\n",
        "def collate_fn(data):\n",
        "    triple_tensors = [item['masked_triple'] for item in data]\n",
        "    label_tensors = [item['label'] for item in data]\n",
        "    return {'masked_triple': triple_tensors, 'label': label_tensors}\n",
        "\n",
        "# Create the data dictionary\n",
        "\n",
        "data_dict = [{'masked_triple': triple, 'label': label} for triple, label in zip(data['masked_triple'], data['label'])]\n",
        "\n",
        "# Create the data loader\n",
        "train_loader = torch.utils.data.DataLoader(data_dict, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219,
          "referenced_widgets": [
            "f0cf223970dd477396ebb17c2fa9df30",
            "fde6643d533b4811a8441148716b69da",
            "f2e834690e234a8a86e50cbae882bd39",
            "3177c5671cb7480599ddef4bd51293fb",
            "d7371bbbf96545ea991cb4d8e2955c75",
            "26fc4cf58b094fec96fc169343db8013",
            "fb3313b6c340478ab25d6d22567f02b7",
            "6d904a9948cc4b6d897b92819d1a85b6",
            "692b920e09b3492b951ee3f6fa28227e",
            "6080684c3a554cd78c9fc76daa6bd685",
            "469bff04a1724edfb21c3b8d447f3201",
            "11e9c36d622d4122b6d8cc77635f4413",
            "52764ce8791f451e90f517376ff6231b",
            "8789ffe8b48b4cc3b49a6673ae08d95c",
            "f79575ea7c8c42d09b2386345c371184",
            "edefd28105114bfd93bf1b2bb7ba1877",
            "fbec3f4269194d4f92bd16f033d6b466",
            "ee656c7d1f334829b6797921012a8c55",
            "2a625523c1be4128a28b98eb134d4bc3",
            "db89e3db64ba47759ba0a12d9b3a987a",
            "23ee155ef3404d70b3fa639103ad97b4",
            "129e4f0305d74a7baef043e77e3d0134",
            "9ff04f0618044e66898298c33f2047a6",
            "da63b55705c24358b5f44eb2d0112dfb",
            "ee1e954a5d464ef68b967b00ee2c7ef3",
            "bb525774331e4602be4decc45a7571c1",
            "7b7bba81ca124e8083e663679b478b39",
            "c7e04f27b2414fb1bf0dec31c7dee23a",
            "c5689690a2e541b7a26218e01a6909d4",
            "bb910e49b748408b84ee7d77669c727e",
            "495bb040af0546aa92322a522855efd5",
            "e3d7734b736c4d44b7d4a4cb17f1a1eb",
            "630cfafc2e33426d8809fee189320b62",
            "c8bc1ec8fba54a76ab731cddcb75a442",
            "cd2f62411c804e0baa234e8e0c74fc3a",
            "67a36bbfb62f4b1486fc7854dbc99298",
            "1b1ba9022ed543208882c0be2784833f",
            "af4f1afcd6fa4651b525e31f59ef2a3b",
            "0b7a8819b0e24c9e9398f75b78661734",
            "793bd161e075433598e1866b1936d605",
            "47c57a2d336241c29c64145406805300",
            "020d9e5ff81c4d48be5e76cb18891390",
            "2eac5c0813594add9d0d093855332d3a",
            "d12061345db84f7783c636b2b5e3a184"
          ]
        },
        "id": "_o4XjE_gQpBz",
        "outputId": "ca3127ca-39f7-4a4b-f13a-1ae0de126f6e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0cf223970dd477396ebb17c2fa9df30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11e9c36d622d4122b6d8cc77635f4413",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ff04f0618044e66898298c33f2047a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8bc1ec8fba54a76ab731cddcb75a442",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "s_wte = SoftEmbedding(tokenizer, model.get_input_embeddings(), device)\n",
        "s_wte.to(device)\n",
        "# s_wte.learned_embedding.weight.requires_grad = True  # Enable gradient computation for the SoftEmbedding weights\n",
        "model.set_input_embeddings(s_wte)\n",
        "model.to(device)\n",
        "\n",
        "# Define your loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define your optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# print(\"parameters:\",model.input_embeddings.parameters())\n",
        "\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxlSyOs7YUWC"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sTUg1BNfYa04",
        "outputId": "7f545b3a-3c0e-466d-cb76-12b39e16f18c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 1/2438 [00:00<10:11,  3.99batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " mask_positions tensor([[ 0,  4],\n",
            "        [ 1,  5],\n",
            "        [ 2,  4],\n",
            "        [ 3,  5],\n",
            "        [ 4,  5],\n",
            "        [ 5,  4],\n",
            "        [ 6, 10],\n",
            "        [ 7,  7]], device='cuda:0')\n",
            "\n",
            " mask_token_logits tensor([[ -6.3824,  -6.3039,  -6.3134,  ...,  -5.4256,  -5.5260,  -6.3814],\n",
            "        [-12.7677, -12.4405, -12.3537,  ..., -10.1908, -10.3768,  -7.3917],\n",
            "        [ -6.4181,  -6.4669,  -6.1966,  ...,  -5.9131,  -5.3796,  -5.0969],\n",
            "        ...,\n",
            "        [ -4.7784,  -4.8262,  -4.7203,  ...,  -4.4492,  -4.3024,  -3.5021],\n",
            "        [-18.3105, -18.5880, -18.6839,  ..., -14.9700, -15.3607,  -8.0037],\n",
            "        [ -8.0554,  -8.2927,  -8.0615,  ...,  -6.0881,  -6.2808,  -5.2628]],\n",
            "       device='cuda:0')\n",
            "labels tensor([ 3883,  2388,  5011,  2269,  2269,  2269, 11062,  2365],\n",
            "       device='cuda:0')\n",
            "predicted_labels tensor([3772, 1007, 1000, 1007, 1007, 3883, 1997, 3364], device='cuda:0')\n",
            "predicted_label  ['acting', ')', '\"', ')', ')', 'actress', 'of', 'actor']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 2/2438 [00:00<10:15,  3.95batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " mask_positions tensor([[0, 6],\n",
            "        [1, 4],\n",
            "        [2, 7],\n",
            "        [3, 2],\n",
            "        [4, 5],\n",
            "        [5, 6],\n",
            "        [6, 4],\n",
            "        [7, 6]], device='cuda:0')\n",
            "\n",
            " mask_token_logits tensor([[-6.0712, -6.0065, -5.9116,  ..., -4.4230, -6.6993, -3.7195],\n",
            "        [-6.0951, -6.0660, -6.1100,  ..., -5.8881, -5.4047, -3.9726],\n",
            "        [-4.9700, -5.1150, -5.0448,  ..., -4.4110, -3.8234, -5.8172],\n",
            "        ...,\n",
            "        [-6.0370, -5.7947, -5.8401,  ..., -4.9044, -6.1585, -3.4996],\n",
            "        [-6.3195, -6.3842, -6.3281,  ..., -5.8451, -5.5342, -3.8215],\n",
            "        [-6.9128, -6.9694, -6.9227,  ..., -6.7296, -6.5282, -3.9347]],\n",
            "       device='cuda:0')\n",
            "labels tensor([2269, 3364, 2269, 2269, 2269, 3364, 2269, 2269], device='cuda:0')\n",
            "predicted_labels tensor([ 5348,  1012,  7762, 11748,  2015,  1012,  1000,  1000],\n",
            "       device='cuda:0')\n",
            "predicted_label  ['juan', '.', 'manuel', 'val', '##s', '.', '\"', '\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 3/2438 [00:00<10:11,  3.98batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " mask_positions tensor([[0, 5],\n",
            "        [1, 9],\n",
            "        [2, 4],\n",
            "        [3, 5],\n",
            "        [4, 4],\n",
            "        [5, 6],\n",
            "        [6, 6],\n",
            "        [7, 5]], device='cuda:0')\n",
            "\n",
            " mask_token_logits tensor([[-7.3562, -7.3285, -7.2631,  ..., -7.6567, -8.5106, -4.3380],\n",
            "        [-9.1891, -9.3458, -9.1652,  ..., -8.5337, -9.3880, -2.3002],\n",
            "        [-7.2738, -7.1299, -7.2300,  ..., -6.7712, -6.7133, -5.0466],\n",
            "        ...,\n",
            "        [-7.3621, -7.2307, -7.3101,  ..., -6.3387, -5.9449, -3.6265],\n",
            "        [-7.7758, -7.7432, -7.6247,  ..., -7.4682, -8.1875, -2.6293],\n",
            "        [-7.2823, -7.1956, -7.1474,  ..., -7.5639, -8.0125, -4.8480]],\n",
            "       device='cuda:0')\n",
            "labels tensor([2269, 2269, 2269, 2388, 3883, 2388, 2269, 2269], device='cuda:0')\n",
            "predicted_labels tensor([ 1011,  2696,  1000,  1011,  1000,  1000, 10722,  1011],\n",
            "       device='cuda:0')\n",
            "predicted_label  ['-', '##ta', '\"', '-', '\"', '\"', 'tu', '-']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 4/2438 [00:01<11:14,  3.61batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " mask_positions tensor([[ 0,  5],\n",
            "        [ 1,  5],\n",
            "        [ 2,  6],\n",
            "        [ 3,  5],\n",
            "        [ 4, 12],\n",
            "        [ 5,  8],\n",
            "        [ 6,  8],\n",
            "        [ 7,  7]], device='cuda:0')\n",
            "\n",
            " mask_token_logits tensor([[-6.1322, -6.2838, -6.2975,  ..., -5.8645, -8.1095, -3.8601],\n",
            "        [-6.7358, -6.8633, -6.9383,  ..., -7.1597, -8.1958, -4.6753],\n",
            "        [-2.8892, -2.9802, -2.9664,  ..., -3.3825, -2.8855, -0.8501],\n",
            "        ...,\n",
            "        [-4.5719, -5.0994, -5.0724,  ..., -4.0209, -5.2390,  1.3105],\n",
            "        [-5.3371, -5.5365, -5.6740,  ..., -4.4111, -5.7814,  1.1618],\n",
            "        [-2.9426, -3.2866, -3.1500,  ..., -2.9610, -2.2995, -3.5965]],\n",
            "       device='cuda:0')\n",
            "labels tensor([3677, 3364, 2269, 3364, 2269, 2269, 2269, 3364], device='cuda:0')\n",
            "predicted_labels tensor([ 1095,  1010,  8962,  1000, 29653,  2819,  2819, 11124],\n",
            "       device='cuda:0')\n",
            "predicted_label  ['×', ',', 'pot', '\"', '##ª', '##um', '##um', '##eri']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 5/2438 [00:01<10:54,  3.72batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " mask_positions tensor([[0, 3],\n",
            "        [1, 7],\n",
            "        [2, 5],\n",
            "        [3, 9],\n",
            "        [4, 9],\n",
            "        [5, 9],\n",
            "        [6, 7],\n",
            "        [7, 9]], device='cuda:0')\n",
            "\n",
            " mask_token_logits tensor([[-4.4381, -4.4215, -4.4682,  ..., -5.1119, -4.6195, -1.1377],\n",
            "        [ 5.7838,  5.3000,  5.4964,  ...,  5.0116,  4.3568,  8.9287],\n",
            "        [-7.1148, -7.1145, -7.4236,  ..., -8.1055, -7.0917, -1.2187],\n",
            "        ...,\n",
            "        [ 6.4041,  6.1282,  6.2591,  ...,  5.9109,  5.7375,  9.1724],\n",
            "        [ 5.2202,  4.7446,  4.7224,  ...,  4.0379,  4.3550,  6.5617],\n",
            "        [ 3.7039,  3.3402,  3.2352,  ...,  3.1318,  2.1897,  7.8530]],\n",
            "       device='cuda:0')\n",
            "labels tensor([2269, 2365, 2269, 2269, 2388, 2388, 2269, 2388], device='cuda:0')\n",
            "predicted_labels tensor([ 1010,   100,  1012, 29653, 29651, 22931,   100, 29653],\n",
            "       device='cuda:0')\n",
            "predicted_label  [',', '[UNK]', '.', '##ª', '##¨', 'antibodies', '[UNK]', '##ª']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 6/2438 [00:01<10:53,  3.72batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " mask_positions tensor([[ 0,  6],\n",
            "        [ 1,  6],\n",
            "        [ 2,  9],\n",
            "        [ 3,  7],\n",
            "        [ 4,  7],\n",
            "        [ 5,  5],\n",
            "        [ 6,  4],\n",
            "        [ 7, 11]], device='cuda:0')\n",
            "\n",
            " mask_token_logits tensor([[ -6.0029,  -5.8260,  -5.8320,  ...,  -5.8164,  -6.8427,  -3.8348],\n",
            "        [ -5.6371,  -5.5067,  -5.5656,  ...,  -5.5728,  -6.7881,  -3.0286],\n",
            "        [ -7.1331,  -7.0327,  -6.9876,  ...,  -7.5015,  -7.1799,  -6.1062],\n",
            "        ...,\n",
            "        [ -7.8852,  -8.0425,  -8.0982,  ...,  -7.7921,  -7.4175,  -5.2233],\n",
            "        [-12.1812, -12.4561, -12.6897,  ..., -11.9986, -10.4507,  -9.2595],\n",
            "        [  0.0326,  -0.1649,  -0.2278,  ...,  -0.9706,  -0.5247,   3.1064]],\n",
            "       device='cuda:0')\n",
            "labels tensor([2269, 2388, 2269, 2269, 2269, 3364, 2269, 2269], device='cuda:0')\n",
            "predicted_labels tensor([ 1010,  1010, 15966,  4079,  4079, 15966,  2139,  1149],\n",
            "       device='cuda:0')\n",
            "predicted_label  [',', ',', 'wit', 'simon', 'simon', 'wit', 'de', 'ˈ']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 7/2438 [00:01<10:51,  3.73batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " mask_positions tensor([[0, 2],\n",
            "        [1, 4],\n",
            "        [2, 4],\n",
            "        [3, 4],\n",
            "        [4, 4],\n",
            "        [5, 3],\n",
            "        [6, 7],\n",
            "        [7, 5]], device='cuda:0')\n",
            "\n",
            " mask_token_logits tensor([[-4.4559, -4.3763, -4.5545,  ..., -3.6323, -3.4793, -1.1110],\n",
            "        [-5.7046, -6.2758, -5.8890,  ..., -5.7065, -6.3404, -4.9024],\n",
            "        [-6.9030, -7.2734, -7.0418,  ..., -6.1628, -7.2002, -3.6040],\n",
            "        ...,\n",
            "        [-6.5432, -6.6436, -6.4766,  ..., -5.9289, -5.4427, -4.0624],\n",
            "        [-6.3769, -6.5482, -6.2480,  ..., -4.8471, -6.2093, -3.9494],\n",
            "        [-8.1663, -8.8895, -8.4464,  ..., -7.5459, -8.3997, -5.3600]],\n",
            "       device='cuda:0')\n",
            "labels tensor([2365, 3364, 2269, 3364, 2388, 2269, 2269, 2269], device='cuda:0')\n",
            "predicted_labels tensor([15897,  2638,  1011,  1024,  1998,  1012,  2023,  2009],\n",
            "       device='cuda:0')\n",
            "predicted_label  ['chiefly', '##ne', '-', ':', 'and', '.', 'this', 'it']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 8/2438 [00:02<10:53,  3.72batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " mask_positions tensor([[0, 2],\n",
            "        [1, 3],\n",
            "        [2, 8],\n",
            "        [3, 4],\n",
            "        [4, 6],\n",
            "        [5, 6],\n",
            "        [6, 8],\n",
            "        [7, 4]], device='cuda:0')\n",
            "\n",
            " mask_token_logits tensor([[-5.8008, -5.7109, -5.6467,  ..., -6.0016, -6.5881, -4.5866],\n",
            "        [-6.5217, -6.7125, -6.6963,  ..., -7.3144, -7.2918, -3.9761],\n",
            "        [ 6.6827,  6.2874,  6.0564,  ...,  7.0578,  4.8281,  7.5941],\n",
            "        ...,\n",
            "        [-9.8807, -9.4202, -9.4538,  ..., -7.1984, -8.2479, -7.5629],\n",
            "        [10.9023, 10.7020, 10.7643,  ..., 10.3482,  9.1432, 11.3458],\n",
            "        [-4.6874, -4.6249, -4.5423,  ..., -4.0267, -5.1512, -4.2554]],\n",
            "       device='cuda:0')\n",
            "labels tensor([2388, 2269, 2269, 3364, 2269, 2269, 2269, 3750], device='cuda:0')\n",
            "predicted_labels tensor([ 1010, 20377, 30035,  8202,  1012,  1012, 29653,  2669],\n",
            "       device='cuda:0')\n",
            "predicted_label  [',', 'bis', '##ᵉ', '##mon', '.', '.', '##ª', '##ton']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 9/2438 [00:02<11:05,  3.65batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " mask_positions tensor([[0, 4],\n",
            "        [1, 7],\n",
            "        [2, 9],\n",
            "        [3, 5],\n",
            "        [4, 6],\n",
            "        [5, 4],\n",
            "        [6, 6],\n",
            "        [7, 7]], device='cuda:0')\n",
            "\n",
            " mask_token_logits tensor([[-8.0535, -8.2596, -7.8989,  ..., -7.2782, -7.0633, -4.4812],\n",
            "        [-5.2107, -4.7282, -5.0854,  ..., -5.3535, -4.2850, -3.4282],\n",
            "        [-9.2336, -8.8427, -8.8995,  ..., -6.7304, -7.2694, -9.6242],\n",
            "        ...,\n",
            "        [-7.1121, -7.3039, -7.1576,  ..., -7.8774, -6.4014, -4.1722],\n",
            "        [-7.8429, -7.7248, -7.5089,  ..., -5.7206, -4.3461, -7.5254],\n",
            "        [-5.4844, -5.6013, -5.6854,  ..., -5.0500, -3.3998, -4.3460]],\n",
            "       device='cuda:0')\n",
            "labels tensor([ 3364,  2269,  2388,  2269,  2269,  2269,  2269, 10248],\n",
            "       device='cuda:0')\n",
            "predicted_labels tensor([ 2011, 22084,  1012,  6754, 12631,  1006, 12631, 22084],\n",
            "       device='cuda:0')\n",
            "predicted_label  ['by', '##nea', '.', 'greg', 'kin', '(', 'kin', '##nea']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-39bed3407bbb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1359\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-620044d76070>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDepTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mentities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node_by_ner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PERSON\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc, processors)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, doc, processors)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbulk_process\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbulk\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/pipeline/pos_processor.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mpreds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_orig_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/models/pos/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, batch, unsort)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordchars_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_orig_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentlens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordlens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mupos_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'upos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mxpos_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xpos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/models/pos/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, word_orig_idx, sentlens, wordlens, text)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mxpos_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclffunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpos_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpos_hid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpos_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpos_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpos_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mufeats_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stanza/models/pos/model.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpretrained_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_predicted = 0\n",
        "    total_true = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\", ncols=80,\n",
        "                        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        # Skip the last batch if its size is different\n",
        "        # print(batch['masked_triple'])\n",
        "        inputs = tokenizer(batch['masked_triple'], return_tensors=\"pt\", padding=True).to(device)\n",
        "        labels = tokenizer(batch['label'], return_tensors=\"pt\", padding=True, add_special_tokens=False)['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Get the positions of the [mask] tokens\n",
        "        mask_positions = (inputs[\"input_ids\"] == tokenizer.mask_token_id).nonzero()\n",
        "        print('\\n mask_positions',mask_positions)\n",
        "\n",
        "        # Ensure the number of mask positions matches the number of labels\n",
        "        if mask_positions.shape[0] > labels.shape[0]:\n",
        "            mask_positions = mask_positions[:labels.shape[0]]\n",
        "        elif mask_positions.shape[0] < labels.shape[0]:\n",
        "            labels = labels[:mask_positions.shape[0]]\n",
        "\n",
        "        # Extract the logits for the [mask] tokens\n",
        "        mask_token_logits = logits[mask_positions[:, 0], mask_positions[:, 1]]\n",
        "\n",
        "        # Reshape the mask_token_logits to (batch_size, num_tokens)\n",
        "        mask_token_logits = mask_token_logits.view(-1, mask_token_logits.size(1))\n",
        "\n",
        "        # Compute the loss\n",
        "        print('mask_token_logits',mask_token_logits)\n",
        "        print('labels',labels)\n",
        "        loss = criterion(mask_token_logits, labels)\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.requires_grad = True\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Compute accuracy and precision\n",
        "        predicted_labels = mask_token_logits.argmax(dim=1)\n",
        "        print('predicted_labels',predicted_labels)\n",
        "        predicted = tokenizer.convert_ids_to_tokens(predicted_labels)\n",
        "        print('predicted_label ',predicted )\n",
        "\n",
        "\n",
        "        correct_predictions = (predicted_labels == labels).sum().item()\n",
        "        total_correct += correct_predictions\n",
        "        total_predicted += predicted_labels.shape[0]\n",
        "        total_true += labels.shape[0]\n",
        "\n",
        "        # Update the progress bar\n",
        "        progress_bar.set_postfix({\"Loss\": loss.item()})\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Calculate accuracy and precision\n",
        "    accuracy = total_correct / total_predicted if total_predicted > 0 else 0.0\n",
        "    precision = total_correct / total_true if total_true > 0 else 0.0\n",
        "\n",
        "    # Print training progress\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss} - Accuracy: {accuracy} - Precision: {precision}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bjs4nW8J6PN9",
        "outputId": "28c549d0-51ab-40df-a6bc-a1fd5ae35f47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 2/2438 [00:00<06:00,  6.75batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted_label  -\n",
            "predicted_label  ##thus\n",
            "predicted_label  ##trip\n",
            "predicted_label  ⊕\n",
            "predicted_label  -\n",
            "predicted_label  .\n",
            "predicted_label  -\n",
            "predicted_label  ##ᵉ\n",
            "8\n",
            "tensor([ 1011., 19877., 24901.,  1612.,  1011.,  1012.,  1011., 30035.],\n",
            "       device='cuda:0')\n",
            "tensor([2269, 2269, 2269, 2269, 2269, 2684, 2388, 3159], device='cuda:0')\n",
            "predicted_label  /\n",
            "predicted_label  flora\n",
            "predicted_label  all\n",
            "predicted_label  and\n",
            "predicted_label  all\n",
            "predicted_label  this\n",
            "predicted_label  ,\n",
            "predicted_label  ulysses\n",
            "8\n",
            "tensor([ 1013., 10088.,  2035.,  1998.,  2035.,  2023.,  1010., 22784.],\n",
            "       device='cuda:0')\n",
            "tensor([3364, 2269, 2269, 2269, 2388, 2269, 3677, 2269], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 4/2438 [00:00<06:52,  5.91batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted_label  coach\n",
            "predicted_label  ##la\n",
            "predicted_label  ##la\n",
            "predicted_label  .\n",
            "predicted_label  et\n",
            "predicted_label  ,\n",
            "predicted_label  \"\n",
            "predicted_label  ##z\n",
            "8\n",
            "tensor([2873., 2721., 2721., 1012., 3802., 1010., 1000., 2480.],\n",
            "       device='cuda:0')\n",
            "tensor([2269, 2269, 2269, 2269, 3364, 2269, 2269, 2269], device='cuda:0')\n",
            "predicted_label  actor\n",
            "predicted_label  ##guchi\n",
            "predicted_label  ##uy\n",
            "predicted_label  yu\n",
            "predicted_label  z\n",
            "predicted_label  ma\n",
            "predicted_label  \"\n",
            "predicted_label  in\n",
            "8\n",
            "tensor([ 3364., 16918., 26230.,  9805.,  1062.,  5003.,  1000.,  1999.],\n",
            "       device='cuda:0')\n",
            "tensor([3364, 2388, 2269, 2269, 2269, 2269, 2269, 3364], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/1:   0%|                            | 6/2438 [00:00<06:36,  6.14batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted_label  emperor\n",
            "predicted_label  ##ª\n",
            "predicted_label  ##rian\n",
            "predicted_label  tr\n",
            "predicted_label  .\n",
            "predicted_label  ptolemy\n",
            "predicted_label  [UNK]\n",
            "predicted_label  replaces\n",
            "8\n",
            "tensor([ 3750., 29653.,  6862., 19817.,  1012., 23517.,   100., 20736.],\n",
            "       device='cuda:0')\n",
            "tensor([3750, 2269, 2269, 2388, 2269, 2269, 2269, 2269], device='cuda:0')\n",
            "predicted_label  and\n",
            "predicted_label  most\n",
            "predicted_label  this\n",
            "predicted_label  ##ably\n",
            "predicted_label  and\n",
            "predicted_label  and\n",
            "predicted_label  most\n",
            "predicted_label  the\n",
            "8\n",
            "tensor([1998., 2087., 2023., 8231., 1998., 1998., 2087., 1996.],\n",
            "       device='cuda:0')\n",
            "tensor([2269, 2269, 2269, 2269, 2269, 2269, 2269, 2388], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 1/1:   0%|                            | 6/2438 [00:01<07:29,  5.41batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted_label  ##a\n",
            "predicted_label  ,\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-57bfbc06ddd6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Iterate over the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masked_triple'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mmasked_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mmask_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mpredicted_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 2 elements cannot be converted to Scalar"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_predicted = 0\n",
        "    total_true = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\", ncols=80,\n",
        "                        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        inputs = tokenizer(batch['masked_triple'], return_tensors=\"pt\", padding=True).to(device)\n",
        "        labels = tokenizer(batch['label'], return_tensors=\"pt\", padding=True, add_special_tokens=False)['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        # print('\\n logits',logits.size())\n",
        "\n",
        "        mask_token_logits = []\n",
        "        mask_positions = []\n",
        "        # Iterate over the batch\n",
        "        for i in range(len(batch['masked_triple'])):\n",
        "            masked_index = (inputs.input_ids[i] == tokenizer.mask_token_id).nonzero().item()\n",
        "            mask_positions.append(masked_index)\n",
        "            predicted_token_index = torch.argmax(logits[i, masked_index]).item()\n",
        "            mask_token_logits.append(predicted_token_index)\n",
        "            predicted_label = tokenizer.convert_ids_to_tokens(predicted_token_index)\n",
        "            print('predicted_label ',predicted_label )\n",
        "\n",
        "        print(len(batch['masked_triple']))\n",
        "        mask_token_logits = torch.tensor(mask_token_logits).to(device).float()\n",
        "        mask_positions = torch.tensor(mask_positions).to(device)\n",
        "        print(mask_token_logits)\n",
        "        print(labels)\n",
        "        labels = labels.float()\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(mask_token_logits, labels)\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.requires_grad = True\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Compute accuracy and precision\n",
        "        predicted_labels = mask_token_logits\n",
        "        correct_predictions = (predicted_labels == labels).sum().item()\n",
        "        total_correct += correct_predictions\n",
        "        total_predicted += predicted_labels.shape[0]\n",
        "        total_true += labels.shape[0]\n",
        "\n",
        "        # Update the progress bar\n",
        "        progress_bar.set_postfix({\"Loss\": loss.item()})\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Calculate accuracy and precision\n",
        "    accuracy = total_correct / total_predicted if total_predicted > 0 else 0.0\n",
        "    precision = total_correct / total_true if total_true > 0 else 0.0\n",
        "\n",
        "    # Print training progress\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss} - Accuracy: {accuracy} - Precision: {precision}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "iaMJIFRyQFna",
        "outputId": "07c5811d-4617-42d7-d7cb-3ea2214ba621"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a9332300463a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# torch.save(model, model_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model_path = '/content/gdrive/MyDrive/model.pth'\n",
        "# torch.save(model, model_path)\n",
        "\n",
        "model.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p09ujitiQ4wm",
        "outputId": "d89974ab-c565-4a52-87d2-e42b70d3d744"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: maria [MASK] john\n",
            "Predicted token for [MASK]: and\n",
            "\n",
            "Input: hello [MASK] world\n",
            "Predicted token for [MASK]: ,\n",
            "\n",
            "Input: I [MASK] a book\n",
            "Predicted token for [MASK]: have\n",
            "\n",
            "Input: the cat [MASK] the mouse\n",
            "Predicted token for [MASK]: and\n",
            "\n",
            "Input: where is [MASK]\n",
            "Predicted token for [MASK]: .\n",
            "\n",
            "Input: [MASK] is my dog\n",
            "Predicted token for [MASK]: this\n",
            "\n",
            "Input: can [MASK] help me\n",
            "Predicted token for [MASK]: you\n",
            "\n",
            "Input: open the [MASK]\n",
            "Predicted token for [MASK]: .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "# Define your input texts as a batch\n",
        "input_texts = ['maria [MASK] john', 'hello [MASK] world', 'I [MASK] a book', 'the cat [MASK] the mouse', 'where is [MASK]', '[MASK] is my dog', 'can [MASK] help me', 'open the [MASK]']\n",
        "\n",
        "# Tokenize the input batch\n",
        "input_ids = tokenizer.batch_encode_plus(input_texts, add_special_tokens=True, padding='longest', return_tensors='pt')\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids.input_ids)\n",
        "    predictions = outputs.logits\n",
        "\n",
        "# Iterate over the batch\n",
        "for i in range(len(input_texts)):\n",
        "    # Find the predicted token for the masked position in each input\n",
        "    masked_index = (input_ids.input_ids[i] == tokenizer.mask_token_id).nonzero().item()\n",
        "    predicted_token_index = torch.argmax(predictions[i, masked_index]).item()\n",
        "    predicted_token = tokenizer.convert_ids_to_tokens(predicted_token_index)\n",
        "\n",
        "    # Print the predicted token for each input\n",
        "    print(f\"Input: {input_texts[i]}\")\n",
        "    print(\"Predicted token for [MASK]:\", predicted_token)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ihx-aSRxCqcD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "020d9e5ff81c4d48be5e76cb18891390": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b7a8819b0e24c9e9398f75b78661734": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e9c36d622d4122b6d8cc77635f4413": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52764ce8791f451e90f517376ff6231b",
              "IPY_MODEL_8789ffe8b48b4cc3b49a6673ae08d95c",
              "IPY_MODEL_f79575ea7c8c42d09b2386345c371184"
            ],
            "layout": "IPY_MODEL_edefd28105114bfd93bf1b2bb7ba1877"
          }
        },
        "129e4f0305d74a7baef043e77e3d0134": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b1ba9022ed543208882c0be2784833f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eac5c0813594add9d0d093855332d3a",
            "placeholder": "​",
            "style": "IPY_MODEL_d12061345db84f7783c636b2b5e3a184",
            "value": " 440M/440M [00:01&lt;00:00, 330MB/s]"
          }
        },
        "23ee155ef3404d70b3fa639103ad97b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26fc4cf58b094fec96fc169343db8013": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a625523c1be4128a28b98eb134d4bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eac5c0813594add9d0d093855332d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3177c5671cb7480599ddef4bd51293fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6080684c3a554cd78c9fc76daa6bd685",
            "placeholder": "​",
            "style": "IPY_MODEL_469bff04a1724edfb21c3b8d447f3201",
            "value": " 232k/? [00:00&lt;00:00, 563kB/s]"
          }
        },
        "469bff04a1724edfb21c3b8d447f3201": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47c57a2d336241c29c64145406805300": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "495bb040af0546aa92322a522855efd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52764ce8791f451e90f517376ff6231b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbec3f4269194d4f92bd16f033d6b466",
            "placeholder": "​",
            "style": "IPY_MODEL_ee656c7d1f334829b6797921012a8c55",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "6080684c3a554cd78c9fc76daa6bd685": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "630cfafc2e33426d8809fee189320b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67a36bbfb62f4b1486fc7854dbc99298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c57a2d336241c29c64145406805300",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_020d9e5ff81c4d48be5e76cb18891390",
            "value": 440449768
          }
        },
        "692b920e09b3492b951ee3f6fa28227e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d904a9948cc4b6d897b92819d1a85b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "793bd161e075433598e1866b1936d605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b7bba81ca124e8083e663679b478b39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8789ffe8b48b4cc3b49a6673ae08d95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a625523c1be4128a28b98eb134d4bc3",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db89e3db64ba47759ba0a12d9b3a987a",
            "value": 28
          }
        },
        "9ff04f0618044e66898298c33f2047a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da63b55705c24358b5f44eb2d0112dfb",
              "IPY_MODEL_ee1e954a5d464ef68b967b00ee2c7ef3",
              "IPY_MODEL_bb525774331e4602be4decc45a7571c1"
            ],
            "layout": "IPY_MODEL_7b7bba81ca124e8083e663679b478b39"
          }
        },
        "af4f1afcd6fa4651b525e31f59ef2a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb525774331e4602be4decc45a7571c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3d7734b736c4d44b7d4a4cb17f1a1eb",
            "placeholder": "​",
            "style": "IPY_MODEL_630cfafc2e33426d8809fee189320b62",
            "value": " 570/570 [00:00&lt;00:00, 23.4kB/s]"
          }
        },
        "bb910e49b748408b84ee7d77669c727e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5689690a2e541b7a26218e01a6909d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7e04f27b2414fb1bf0dec31c7dee23a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8bc1ec8fba54a76ab731cddcb75a442": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd2f62411c804e0baa234e8e0c74fc3a",
              "IPY_MODEL_67a36bbfb62f4b1486fc7854dbc99298",
              "IPY_MODEL_1b1ba9022ed543208882c0be2784833f"
            ],
            "layout": "IPY_MODEL_af4f1afcd6fa4651b525e31f59ef2a3b"
          }
        },
        "cd2f62411c804e0baa234e8e0c74fc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b7a8819b0e24c9e9398f75b78661734",
            "placeholder": "​",
            "style": "IPY_MODEL_793bd161e075433598e1866b1936d605",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "d12061345db84f7783c636b2b5e3a184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7371bbbf96545ea991cb4d8e2955c75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da63b55705c24358b5f44eb2d0112dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7e04f27b2414fb1bf0dec31c7dee23a",
            "placeholder": "​",
            "style": "IPY_MODEL_c5689690a2e541b7a26218e01a6909d4",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "db89e3db64ba47759ba0a12d9b3a987a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3d7734b736c4d44b7d4a4cb17f1a1eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edefd28105114bfd93bf1b2bb7ba1877": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1e954a5d464ef68b967b00ee2c7ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb910e49b748408b84ee7d77669c727e",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_495bb040af0546aa92322a522855efd5",
            "value": 570
          }
        },
        "ee656c7d1f334829b6797921012a8c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0cf223970dd477396ebb17c2fa9df30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fde6643d533b4811a8441148716b69da",
              "IPY_MODEL_f2e834690e234a8a86e50cbae882bd39",
              "IPY_MODEL_3177c5671cb7480599ddef4bd51293fb"
            ],
            "layout": "IPY_MODEL_d7371bbbf96545ea991cb4d8e2955c75"
          }
        },
        "f2e834690e234a8a86e50cbae882bd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d904a9948cc4b6d897b92819d1a85b6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_692b920e09b3492b951ee3f6fa28227e",
            "value": 1
          }
        },
        "f79575ea7c8c42d09b2386345c371184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ee155ef3404d70b3fa639103ad97b4",
            "placeholder": "​",
            "style": "IPY_MODEL_129e4f0305d74a7baef043e77e3d0134",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.14kB/s]"
          }
        },
        "fb3313b6c340478ab25d6d22567f02b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbec3f4269194d4f92bd16f033d6b466": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fde6643d533b4811a8441148716b69da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26fc4cf58b094fec96fc169343db8013",
            "placeholder": "​",
            "style": "IPY_MODEL_fb3313b6c340478ab25d6d22567f02b7",
            "value": "Downloading (…)solve/main/vocab.txt: "
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}